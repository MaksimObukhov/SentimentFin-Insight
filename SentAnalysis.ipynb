{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "%reset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2023-08-12T21:22:00.990543Z",
     "start_time": "2023-08-12T21:21:58.659930Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Sentiment classifier"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Libraries"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'DataCollatorWithPadding' from 'transformers' (/Users/maksim/anaconda3/lib/python3.11/site-packages/transformers/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mImportError\u001B[0m                               Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[2], line 6\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mmatplotlib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpyplot\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mplt\u001B[39;00m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msklearn\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmodel_selection\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m train_test_split\n\u001B[0;32m----> 6\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtransformers\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m AutoTokenizer, TFAutoModelForSequenceClassification, DataCollatorWithPadding\n\u001B[1;32m      8\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mtf\u001B[39;00m\n\u001B[1;32m      9\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mkeras\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m optimizers, metrics, losses\n",
      "\u001B[0;31mImportError\u001B[0m: cannot import name 'DataCollatorWithPadding' from 'transformers' (/Users/maksim/anaconda3/lib/python3.11/site-packages/transformers/__init__.py)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from transformers import AutoTokenizer, TFAutoModelForSequenceClassification, DataCollatorWithPadding\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import optimizers, metrics, losses\n",
    "\n",
    "from wordcloud import WordCloud,STOPWORDS\n",
    "# from datasets import DatasetDict\n",
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2023-10-10T10:17:57.781499Z",
     "start_time": "2023-10-10T10:17:57.768749Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Settings"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# If True, loads weights of model from my_model.h5 file. No need to train again.\n",
    "MODEL_SAVED = False\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams[\"figure.figsize\"] = (12, 8)\n",
    "plt.style.use(\"bmh\")\n",
    "plt.rcParams[\"axes.facecolor\"] = \"white\"\n",
    "plt.rcParams[\"axes.edgecolor\"] = \"black\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "start_time": "2023-08-12T21:22:01.000226Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Dataset preparing"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Dataset building"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# raw_data = pd.read_csv('financial_phrasebank.txt', sep='\\n', header=None)\n",
    "# df = raw_data.copy()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "start_time": "2023-08-12T21:22:01.001459Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "path = '/Users/maksim/Documents/VSE/4. Semester/TextAnalysis_1/SeminarWork/'\n",
    "with open(path + 'financial_phrasebank.txt', 'r', encoding='UTF-8') as file:\n",
    "    text_string = file.read()\n",
    "\n",
    "lines = text_string.split('\\n')\n",
    "\n",
    "# Create a DataFrame from the lines\n",
    "raw_data = pd.DataFrame({'text': lines})\n",
    "raw_data = raw_data.iloc[:-1]\n",
    "df = raw_data.copy()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "start_time": "2023-08-12T21:22:01.002322Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The data follows text@label pattern. Separate by \"@\"."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = df['text'].str.extract(r'(.*)\\@(.*)', expand=True)\n",
    "df.columns = ['text', 'label']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "start_time": "2023-08-12T21:22:01.003725Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "start_time": "2023-08-12T21:22:01.004693Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "start_time": "2023-08-12T21:22:01.005646Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "No missing data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Mapping label"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Mapping dictionary\n",
    "mapping = {'positive': 1, 'negative': 0, 'neutral': 2}\n",
    "\n",
    "# Apply mapping to the 'label' column\n",
    "df['label'] = df['label'].map(mapping)\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "start_time": "2023-08-12T21:22:01.006479Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Convert as a final dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Splitting the data into training, test and validation as 70%, 20% and 10% respectively"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[12], line 4\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mdask\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m datasets\n\u001B[1;32m      3\u001B[0m \u001B[38;5;66;03m# Splitting the dataframe into train, test, and validation parts\u001B[39;00m\n\u001B[0;32m----> 4\u001B[0m train_df, test_df \u001B[38;5;241m=\u001B[39m train_test_split(df, test_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.3\u001B[39m, random_state\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m42\u001B[39m)\n\u001B[1;32m      5\u001B[0m test_df, val_df \u001B[38;5;241m=\u001B[39m train_test_split(test_df, test_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.33\u001B[39m, random_state\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m42\u001B[39m)\n\u001B[1;32m      7\u001B[0m \u001B[38;5;66;03m# Convert the dataframes to datasets\u001B[39;00m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "from dask import datasets\n",
    "\n",
    "# Splitting the dataframe into train, test, and validation parts\n",
    "train_df, test_df = train_test_split(df, test_size=0.3, random_state=42)\n",
    "test_df, val_df = train_test_split(test_df, test_size=0.33, random_state=42)\n",
    "\n",
    "# Convert the dataframes to datasets\n",
    "train_dataset = datasets.Dataset.from_pandas(train_df, preserve_index=False)\n",
    "test_dataset = datasets.Dataset.from_pandas(test_df, preserve_index=False)\n",
    "val_dataset = datasets.Dataset.from_pandas(val_df, preserve_index=False)\n",
    "\n",
    "# Create a DatasetDict object\n",
    "dataset = datasets.DatasetDict({\n",
    "    'train': train_dataset,\n",
    "    'test': test_dataset,\n",
    "    'validation': val_dataset\n",
    "})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2023-08-12T21:21:56.101537Z",
     "start_time": "2023-08-12T21:21:55.929766Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2023-08-12T20:55:09.800953Z",
     "start_time": "2023-08-12T20:55:09.774634Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data Understanding"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Label distribution"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "df[\"label\"].value_counts(ascending=True).plot.barh()\n",
    "plt.xlabel('Labels')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Label Distribution')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n",
    "\n",
    "display(df['label'].value_counts())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "start_time": "2023-08-12T20:55:09.776103Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Labels do not equally distributed. Most of the instances are neutral. Negative label is the least frequent."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Word Clouds"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Positive labels"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Sentiment Positive\n",
    "df_pos = df[df['label']==1]\n",
    "words = ' '.join(df_pos['text'].astype(str))\n",
    "cleaned_word = ' '.join([word for word in words.split() if not word.startswith('@')])\n",
    "\n",
    "wordcloud = WordCloud(background_color='white',stopwords=STOPWORDS,\n",
    "                      width=3000, height=2500).generate(''.join(cleaned_word))\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "start_time": "2023-08-12T20:55:09.777808Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Negative labels"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Sentiment Negative\n",
    "df_neg = df[df['label']==0]\n",
    "words = ' '.join(df_neg['text'].astype(str))\n",
    "cleaned_word = ' '.join([word for word in words.split() if not word.startswith('@')])\n",
    "\n",
    "wordcloud = WordCloud(background_color='white',stopwords=STOPWORDS,\n",
    "                      width=3000, height=2500).generate(''.join(cleaned_word))\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "start_time": "2023-08-12T20:55:09.779963Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Neutral labels"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Sentiment Neutral\n",
    "df_neu = df[df['label']==2]\n",
    "words = ' '.join(df_neu['text'].astype(str))\n",
    "cleaned_word = ' '.join([word for word in words.split() if not word.startswith('@')])\n",
    "\n",
    "wordcloud = WordCloud(background_color='white',stopwords=STOPWORDS,\n",
    "                      width=3000, height=2500).generate(''.join(cleaned_word))\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "start_time": "2023-08-12T20:55:09.783783Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data Preprocessing"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Tokenization"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dataset.reset_format()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "start_time": "2023-08-12T20:55:09.785464Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_ckpt = \"distilbert-base-uncased\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "start_time": "2023-08-12T20:55:09.786794Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(pretrained_model_name_or_path=model_ckpt, max_length=512)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "start_time": "2023-08-12T20:55:09.788187Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def tokenize(batch):\n",
    "    return tokenizer(batch[\"text\"], padding=True, truncation=True)\n",
    "\n",
    "tokenized_dataset = dataset.map(tokenize, batched=True, batch_size=None)\n",
    "tokenized_dataset.with_format('tensorflow')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "start_time": "2023-08-12T20:55:09.789367Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(tokenized_dataset[\"train\"][:1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "start_time": "2023-08-12T20:55:09.790245Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model initialization"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, return_tensors=\"tf\")\n",
    "data_collator"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "start_time": "2023-08-12T20:55:09.790841Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tf_train_dataset = tokenized_dataset[\"train\"].to_tf_dataset(\n",
    "    columns=[\"input_ids\", \"attention_mask\"],\n",
    "    label_cols=[\"label\"],\n",
    "    shuffle=True,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=data_collator\n",
    ")\n",
    "\n",
    "tf_valid_dataset = tokenized_dataset[\"validation\"].to_tf_dataset(\n",
    "    columns=[\"input_ids\", \"attention_mask\"],\n",
    "    label_cols=[\"label\"],\n",
    "    shuffle=False,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=data_collator\n",
    ")\n",
    "\n",
    "tf_test_dataset = tokenized_dataset[\"test\"].to_tf_dataset(\n",
    "    columns=[\"input_ids\", \"attention_mask\"],\n",
    "    label_cols=[\"label\"],\n",
    "    shuffle=False,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=data_collator\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "start_time": "2023-08-12T20:55:09.791550Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "num_labels = 3\n",
    "\n",
    "def create_model():\n",
    "    model = TFAutoModelForSequenceClassification.from_pretrained(model_ckpt, num_labels=num_labels)\n",
    "    model.compile(\n",
    "        optimizer=optimizers.Adam(learning_rate=5e-5),\n",
    "        loss=losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "        metrics=metrics.SparseCategoricalAccuracy())\n",
    "    return model\n",
    "\n",
    "if MODEL_SAVED:\n",
    "    model = create_model()\n",
    "    model.load_weights('my_model.h5')\n",
    "else:\n",
    "    model = create_model()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "start_time": "2023-08-12T20:55:09.792036Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "start_time": "2023-08-12T20:55:09.792642Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'MODEL_SAVED' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[8], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m MODEL_SAVED:\n\u001B[1;32m      2\u001B[0m     model\u001B[38;5;241m.\u001B[39mfit(tf_train_dataset,\n\u001B[1;32m      3\u001B[0m               validation_data\u001B[38;5;241m=\u001B[39mtf_valid_dataset,\n\u001B[1;32m      4\u001B[0m               epochs\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m5\u001B[39m)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'MODEL_SAVED' is not defined"
     ]
    }
   ],
   "source": [
    "if not MODEL_SAVED:\n",
    "    model.fit(tf_train_dataset,\n",
    "              validation_data=tf_valid_dataset,\n",
    "              epochs=5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2023-08-12T20:55:04.467260Z",
     "start_time": "2023-08-12T20:55:04.453949Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Test the model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 50ms/step\n",
      "negative\n"
     ]
    }
   ],
   "source": [
    "outputs = model.predict(tokenizer(\"BTC price decreased\")[\"input_ids\"])\n",
    "outputs['logits'][0].tolist()\n",
    "label_int = np.argmax(tf.keras.layers.Softmax()(outputs['logits'][0].tolist()))\n",
    "\n",
    "def get_mapping_value(value):\n",
    "    for key, mapped_value in mapping.items():\n",
    "        if mapped_value == value:\n",
    "            return key\n",
    "    return None\n",
    "\n",
    "print(get_mapping_value(label_int.item()))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model evaluation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 18s 1s/step - loss: 0.2460 - sparse_categorical_accuracy: 0.9222\n",
      "Test set accuracy: 92.22%\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(tf_test_dataset)\n",
    "print(\"Test set accuracy: {:.2f}%\".format(results[1] * 100))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can conclude that the model correctly predicted the label 92.22% of instances. It performs very well."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Topic modeling"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Corpus preparation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['accord gran , compani plan move product russia , although compani grow .', 'new product plant compani would increas capac meet expect increas demand would improv use raw materi therefor increas product profit .']\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Remove stop words\n",
    "stop_words = set(stopwords.words('english'))\n",
    "corpus = df['text'].apply(lambda x: ' '.join([word for word in word_tokenize(x) if word.lower() not in stop_words]))\n",
    "\n",
    "# Create a stemmer object\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "# Perform stemming\n",
    "stemmed_corpus = []\n",
    "for text in corpus:\n",
    "    tokens = word_tokenize(text)  # Tokenize the text into individual words\n",
    "    stemmed_tokens = [stemmer.stem(token) for token in tokens]  # Perform stemming on each token\n",
    "    stemmed_text = ' '.join(stemmed_tokens)  # Join the stemmed tokens back into a string\n",
    "    stemmed_corpus.append(stemmed_text)\n",
    "\n",
    "# Remove numbers\n",
    "stemmed_corpus = [re.sub(r'\\d+', '', text) for text in stemmed_corpus]\n",
    "\n",
    "print(stemmed_corpus[:2])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count_vect = CountVectorizer(max_df=0.8, min_df=2)\n",
    "doc_term_matrix = count_vect.fit_transform(stemmed_corpus)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We specify to only include those words that appear in less than 80% of the document and appear in at least 2 documents. We also remove any numbers, perform stemming, and remove all the stop words as they do not really contribute to topic modeling.\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [
    {
     "data": {
      "text/plain": "LatentDirichletAllocation(n_components=5, random_state=42)",
      "text/html": "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LatentDirichletAllocation(n_components=5, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LatentDirichletAllocation</label><div class=\"sk-toggleable__content\"><pre>LatentDirichletAllocation(n_components=5, random_state=42)</pre></div></div></div></div></div>"
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "LDA = LatentDirichletAllocation(n_components=5, random_state=42)\n",
    "LDA.fit(doc_term_matrix)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The parameter n_components specifies the number of categories, or topics, that we want our text to be divided into, in our case it is 3. The parameter random_state is set to 42 so that we get the same results"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 words for topic #0:\n",
      "['oyj', 'contract', 'said', 'finnish', 'servic']\n",
      "\n",
      "\n",
      "Top 5 words for topic #1:\n",
      "['sale', 'net', 'profit', 'mn', 'eur']\n",
      "\n",
      "\n",
      "Top 5 words for topic #2:\n",
      "['share', 'oper', 'product', 'also', 'compani']\n",
      "\n",
      "\n",
      "Top 5 words for topic #3:\n",
      "['finnish', 'euro', 'compani', 'mln', 'share']\n",
      "\n",
      "\n",
      "Top 5 words for topic #4:\n",
      "['nokia', 'finland', 'oper', 'start', 'compani']\n"
     ]
    }
   ],
   "source": [
    "for i,topic in enumerate(LDA.components_):\n",
    "    print(f'Top 5 words for topic #{i}:')\n",
    "    print([count_vect.get_feature_names_out()[i] for i in topic.argsort()[-5:]])\n",
    "    print('\\n')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We obtain 3 topics and 5 the most popular words per topic"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Collocation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['accord', 'gran', 'compani', 'plan', 'move', 'product', 'russia', 'although', 'compani', 'grow', 'new', 'product', 'plant', 'compani', 'would', 'increas', 'capac', 'meet', 'expect', 'increas']\n"
     ]
    }
   ],
   "source": [
    "words = []\n",
    "for sublist in stemmed_corpus:\n",
    "    matches = re.findall(r'\\w+', sublist)\n",
    "    words.extend(matches)\n",
    "\n",
    "print(words[:20])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "net sale; oper profit; correspond period; eur million; euro mln; mln\n",
      "euro; oyj hel; per share; third quarter; omx helsinki\n"
     ]
    }
   ],
   "source": [
    "# prints the 10 most common bigrams\n",
    "import nltk\n",
    "colText = nltk.Text(words)\n",
    "colText.collocations(10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words: 42190\n",
      "Number of bigrams: 42189\n"
     ]
    }
   ],
   "source": [
    "colBigrams = list(nltk.ngrams(colText, 2))\n",
    "print(\"Number of words:\", len(words))\n",
    "print(\"Number of bigrams:\", len(colBigrams))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here we  check to make sure the bigram function has gone through and counted the entire text. Having one less ngram is correct because of the way in which the ngrams are generated word-by-word in the test above"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('forecast', 1.0)\n",
      "('could', 1.0)\n",
      "('loan', 1.0)\n",
      "('welcom', 1.0)\n",
      "('think', 1.0)\n",
      "('ls', 0.9461490187934268)\n",
      "('thousand', 0.9147372572392014)\n",
      "('sekm', 0.885271235482454)\n",
      "('capman', 0.885127636876205)\n",
      "('xa', 0.8571208251401715)\n",
      "('aspo', 0.8548037030857015)\n",
      "('catalyst', 0.8535141508484155)\n",
      "('nd', 0.8377859485034687)\n",
      "('kemira', 0.8310511568377097)\n",
      "('billion', 0.8284977537700866)\n",
      "('mln', 0.8224237824962862)\n",
      "('onlin', 0.822311325120984)\n",
      "('digia', 0.8183396283172262)\n",
      "('dopplr', 0.8175189047653515)\n",
      "('nokia', 0.8114146298096994)\n",
      "('appoint', 0.8080702049604045)\n",
      "('cap', 0.8012149309251502)\n",
      "('nwc', 0.8012052708494896)\n",
      "('eurm', 0.8011543501013417)\n",
      "('sek', 0.8005964749561502)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from collections import defaultdict\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Compute the TF-IDF matrix for the corpus\n",
    "tfidf_matrix = vectorizer.fit_transform(stemmed_corpus)\n",
    "\n",
    "# Get the feature names (terms)\n",
    "terms = vectorizer.get_feature_names_out()\n",
    "\n",
    "# Identify collocations based on TF-IDF scores\n",
    "collocations = defaultdict(float)\n",
    "for i, doc in enumerate(corpus):\n",
    "    feature_index = tfidf_matrix[i, :].nonzero()[1]\n",
    "    tfidf_scores = zip(feature_index, [tfidf_matrix[i, x] for x in feature_index])\n",
    "\n",
    "    for term_idx, score in tfidf_scores:\n",
    "        term = terms[term_idx]\n",
    "        collocations[term] = max(collocations[term], score)\n",
    "\n",
    "# Sort collocations by TF-IDF score in descending order\n",
    "sorted_collocations = sorted(collocations.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Print the top collocations\n",
    "top_collocations = sorted_collocations[:25]\n",
    "for collocation in top_collocations:\n",
    "    print(collocation)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here is a list of top 25 words by TF-IDF score"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
